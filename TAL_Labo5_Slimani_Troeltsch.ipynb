{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9596f7a87b82732",
   "metadata": {},
   "source": [
    "<img src=\"https://heig-vd.ch/docs/default-source/doc-global-newsletter/2020-slim.svg\" alt=\"HEIG-VD Logo\" width=\"100\" align=\"right\" /> \n",
    "\n",
    "# Cours TAL - Laboratoire 5<br/> Le modèle word2vec et ses applications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e585df9",
   "metadata": {},
   "source": [
    "## Partie 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "### Téléchargement du modèle word2vec pré entrainé sur le corpus de Google News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc121e30a2defb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:53:39.359170Z",
     "start_time": "2025-05-01T21:53:38.961976Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim import downloader as api\n",
    "path_to_file = api.load(\"word2vec-google-news-300\", return_path=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e00a01710ba3ec5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:54:21.810094Z",
     "start_time": "2025-05-01T21:53:40.281320Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "w2v_vectors = KeyedVectors.load_word2vec_format(path_to_file, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c14df69a6edac1",
   "metadata": {},
   "source": [
    "### a. Quelle place en mémoire occupe le processus du notebook avec les vecteurs de mots ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2fe61cf4f5afab5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:54:34.317110Z",
     "start_time": "2025-05-01T21:54:34.307871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du notebook : 3433.23 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Taille du notebook : {w2v_vectors.vectors.nbytes / (1024 ** 2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3105ddbc17f1620",
   "metadata": {},
   "source": [
    "### b. Quelle est la dimension de l’espace vectoriel dans lequel les mots sont représentés ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b472b8c6fa51ec5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:54:36.035848Z",
     "start_time": "2025-05-01T21:54:36.029615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les vecteurs de mots ont une dimension de : 300 dimensions\n"
     ]
    }
   ],
   "source": [
    "print(f\"Les vecteurs de mots ont une dimension de : {w2v_vectors.vector_size} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774852931cee8802",
   "metadata": {},
   "source": [
    "### c. Quelle est la taille du vocabulaire connu du modèle ?  Veuillez afficher cinq mots anglais qui sont dans le vocabulaire et deux qui ne le sont pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8fd57e258d64055",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:54:37.415153Z",
     "start_time": "2025-05-01T21:54:37.408156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Taille du vocabulaire : 3000000 mots\n"
     ]
    }
   ],
   "source": [
    "print(f\" Taille du vocabulaire : {len(w2v_vectors.key_to_index)} mots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b5bb40e79fda7b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:54:38.913712Z",
     "start_time": "2025-05-01T21:54:38.860529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemples de mots connus du modèle : ['spokesman_Liu_Dezheng', 'reusable_bag', 'VV_Vyas_top', 'superbly_conditioned', 'Danny_Elfman_Alice']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "sample_words = random.sample(list(w2v_vectors.key_to_index.keys()), 5)\n",
    "print(\"Exemples de mots connus du modèle :\", sample_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b09fb71957753bd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:54:40.164341Z",
     "start_time": "2025-05-01T21:54:40.139002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ces mots sont-ils dans le vocabulaire ?\n",
      "horloge : Non\n",
      "Horloge : Oui\n",
      "Huitante : Non\n",
      "huitante : Non\n",
      "Altruiste : Non\n",
      "altruiste : Non\n",
      "montre : Oui\n",
      "Montre : Oui\n",
      "MoNtRe : Non\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nC\\'est étonnant que le mot \"horloge\" ne soit pas dans le vocabulaire, car il est très courant en français. De plus, on peut voir que \"Horloge\" est dans le vocabulaire du modèle. Grâce aux tests effectués sur le mot \"montre\", on peut voir que le modèle est sensible à la casse.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown = [\"horloge\", \"Horloge\",\"Huitante\", \"huitante\", \"Altruiste\", \"altruiste\" ,\"montre\", \"Montre\", \"MoNtRe\"]\n",
    "print(\"Ces mots sont-ils dans le vocabulaire ?\")\n",
    "for word in unknown:\n",
    "    print(f\"{word} : {'Oui' if word in w2v_vectors else 'Non'}\")\n",
    "\n",
    "\"\"\"\n",
    "C'est étonnant que le mot \"horloge\" ne soit pas dans le vocabulaire, car il est très courant en français. De plus, on peut voir que \"Horloge\" est dans le vocabulaire du modèle. Grâce aux tests effectués sur le mot \"montre\", on peut voir que le modèle est sensible à la casse.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e4e67d0dfe807b",
   "metadata": {},
   "source": [
    "### d. Quelle est la similarité entre les mots rabbit et carrot ?  Veuillez rappeler comment on mesure les similarités entre deux mots grâce à leurs vecteurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcdf1b60bf236296",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:54:42.667093Z",
     "start_time": "2025-05-01T21:54:42.639425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarité entre les mots 'rabbit' et 'carrot' : 0.3631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nLa similarité entre deux mots est mesurée par le produit scalaire de leurs vecteurs, normalisé par la norme de chacun des vecteurs. En d'autres termes, la similarité entre deux mots est donnée par la formule : Similiarité(a, b) = a * b / ||a|| * ||b||.\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Similarité entre les mots 'rabbit' et 'carrot' : {w2v_vectors.similarity('rabbit', 'carrot'):.4f}\")\n",
    "\n",
    "\"\"\"\n",
    "La similarité entre deux mots est mesurée par le produit scalaire de leurs vecteurs, normalisé par la norme de chacun des vecteurs. En d'autres termes, la similarité entre deux mots est donnée par la formule : Similiarité(a, b) = a * b / ||a|| * ||b||.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96b1e08ab54e11e",
   "metadata": {},
   "source": [
    "### e. Considérez au moins 5 paires de mots anglais, certains proches par leurs sens, d’autres plus éloignés. Pour chaque paire, calculez la similarité entre les deux mots.  Veuillez indiquer si les similarités obtenues correspondent à vos intuitions sur la proximité des sens des mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b13814b86e759a37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:54:46.075359Z",
     "start_time": "2025-05-01T21:54:46.050687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarité entre 'king' et 'queen' : 0.6511\n",
      "Similarité entre 'cat' et 'tiger' : 0.5173\n",
      "Similarité entre 'computer' et 'tree' : 0.1062\n",
      "Similarité entre 'wheel' et 'spider' : 0.1464\n",
      "Similarité entre 'security' et 'byte' : 0.1081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nDe manière générale, les similarités obtenues correspondent à nos intuitions. Toutefois, nous aurions pensé que la similiarité entre \"computer\" et \"tree\"serait plus élevée. Le modèle doit très certaienemnt comprendre le mot \"tree\" comme étant un arbre dans une forêt, et non une structure informatique. Le constat est le même pour \"securtiy\" et \"byte\". Pour ce cas de figure, on peut penser que le score obtenu est légitime car le mot \"security\" est trop général et peut être utilisé dans de nombreux contextes.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pairs = [(\"king\", \"queen\"), (\"cat\", \"tiger\"), (\"computer\", \"tree\"), (\"wheel\", \"spider\"), (\"security\", \"byte\")]\n",
    "\n",
    "for word1, word2 in word_pairs:\n",
    "    similarity = w2v_vectors.similarity(word1, word2)\n",
    "    print(f\"Similarité entre '{word1}' et '{word2}' : {similarity:.4f}\")\n",
    "\n",
    "\"\"\"\n",
    "De manière générale, les similarités obtenues correspondent à nos intuitions. Toutefois, nous aurions pensé que la similiarité entre \"computer\" et \"tree\"serait plus élevée. Le modèle doit très certaienemnt comprendre le mot \"tree\" comme étant un arbre dans une forêt, et non une structure informatique. Le constat est le même pour \"securtiy\" et \"byte\". Pour ce cas de figure, on peut penser que le score obtenu est légitime car le mot \"security\" est trop général et peut être utilisé dans de nombreux contextes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897822d61644fd",
   "metadata": {},
   "source": [
    "### f. Pouvez-vous trouver des mots de sens opposés mais qui sont proches selon le modèle ? Comment expliquez-vous cela ?  Est-ce une qualité ou un défaut du modèle word2vec ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29e5015cbc52d0a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:54:48.849720Z",
     "start_time": "2025-05-01T21:54:48.825554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarité entre 'win' et 'lose' : 0.3951\n",
      "Similarité entre 'day' et 'night' : 0.5070\n",
      "Similarité entre 'love' et 'hate' : 0.6004\n",
      "Similarité entre 'walk' et 'drive' : 0.3630\n",
      "Similarité entre 'up' et 'down' : 0.6397\n",
      "Similarité entre 'happy' et 'sad' : 0.5355\n",
      "Similarité entre 'light' et 'dark' : 0.4713\n",
      "Similarité entre 'success' et 'failure' : 0.3241\n",
      "Similarité entre 'young' et 'old' : 0.4174\n",
      "Similarité entre 'strong' et 'weak' : 0.6157\n",
      "Similarité entre 'enter' et 'exit' : 0.3563\n",
      "Similarité entre 'increase' et 'decrease' : 0.8370\n",
      "Similarité entre 'begin' et 'end' : 0.3478\n",
      "Similarité entre 'open' et 'close' : 0.4637\n",
      "Similarité entre 'true' et 'false' : 0.3709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nDans nos résultats, nous pouvons constater que plusieurs paires de mots opposés ont des similarités étonnamment élevées. Le cas le plus frappant est \"increase\" et \"decrease\" avec un score de 0.84, mais on observe aussi des valeurs élevées pour \"up/down\" (0.64) et \"strong/weak\" (0.62).\\n\\nOn pourrait s\\'attendre à ce que des antonymes aient une similarité plus basse. En réalité, Word2Vec capture les relations contextuelles entre les mots. Dans les textes, ces paires d\\'opposés apparaissent souvent ensemble - quand on parle d\\'augmentation, la diminution est fréquemment mentionnée aussi.\\n\\nPouvons nous voir cela comme une qualité ou un défaut du modèle ? D\\'un côté, cela illustre que Word2Vec comprend les relations conceptuelles entre les mots car les antonymes font bien partie du même champ sémantique / lexicale. D\\'un autre côté, pour des applications comme l\\'analyse de sentiment, cette caractéristique pourrait être problématique. Cela représente davantage une caractéristique fondamentale du modèle qu\\'un véritable défaut.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pairs = [\n",
    "    (\"win\", \"lose\"),\n",
    "    (\"day\", \"night\"),\n",
    "    (\"love\", \"hate\"),\n",
    "    (\"walk\", \"drive\"),\n",
    "    (\"up\", \"down\"),\n",
    "    (\"happy\", \"sad\"),\n",
    "    (\"light\", \"dark\"),\n",
    "    (\"success\", \"failure\"),\n",
    "    (\"young\", \"old\"),\n",
    "    (\"strong\", \"weak\"),\n",
    "    (\"enter\", \"exit\"),\n",
    "    (\"increase\", \"decrease\"),\n",
    "    (\"begin\", \"end\"),\n",
    "    (\"open\", \"close\"),\n",
    "    (\"true\", \"false\")\n",
    "]\n",
    "\n",
    "for word1, word2 in word_pairs:\n",
    "    similarity = w2v_vectors.similarity(word1, word2)\n",
    "    print(f\"Similarité entre '{word1}' et '{word2}' : {similarity:.4f}\")\n",
    "\n",
    "\"\"\"\n",
    "Dans nos résultats, nous pouvons constater que plusieurs paires de mots opposés ont des similarités étonnamment élevées. Le cas le plus frappant est \"increase\" et \"decrease\" avec un score de 0.84, mais on observe aussi des valeurs élevées pour \"up/down\" (0.64) et \"strong/weak\" (0.62).\n",
    "\n",
    "On pourrait s'attendre à ce que des antonymes aient une similarité plus basse. En réalité, Word2Vec capture les relations contextuelles entre les mots. Dans les textes, ces paires d'opposés apparaissent souvent ensemble - quand on parle d'augmentation, la diminution est fréquemment mentionnée aussi.\n",
    "\n",
    "Pouvons nous voir cela comme une qualité ou un défaut du modèle ? D'un côté, cela illustre que Word2Vec comprend les relations conceptuelles entre les mots car les antonymes font bien partie du même champ sémantique / lexicale. D'un autre côté, pour des applications comme l'analyse de sentiment, cette caractéristique pourrait être problématique. Cela représente davantage une caractéristique fondamentale du modèle qu'un véritable défaut.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fe4d7ef4902512",
   "metadata": {},
   "source": [
    "### g. En vous aidant de la documentation de Gensim sur KeyedVectors, obtenez les scores du modèle word2vec sur les données de test WordSimilarity-353. Veuillez rappeler en 1-2 phrases comment les différents scores sont calculés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3adbdf1bb953cc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:54:52.958645Z",
     "start_time": "2025-05-01T21:54:52.537543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrélation de Pearson : 0.6239\n",
      "Corrélation de Spearman : 0.6589\n",
      "Ratio de mots inconnus : 0.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nLa fonction evaluate_word_pairs nous retourne trois métriques principales. Le coefficient de corrélation de Pearson est un tuple contenant le coefficient (un nombre entre -1 et 1) et sa valeur p associée, qui mesure la relation linéaire directe entre les similarités calculées par notre modèle et les jugements humains du dataset. Le coefficient de Spearman est également un tuple avec le coefficient et sa valeur p, mais qui s'intéresse plutôt à la corrélation des rangs (l'ordre) plutôt qu'aux valeurs absolues. Enfin, l'oov_ratio (out-of-vocabulary ratio) est un simple pourcentage qui indique la proportion de paires de mots qui n'existent pas dans le vocabulaire de notre modèle.\\n\\nConcernant les scores, ils sont calculés en comparant les similarités de paires de mots générées par le modèle avec les jugements humains du dataset WordSim-353. Le coefficient de corrélation de Pearson mesure la relation linéaire entre les deux ensembles de scores, tandis que le coefficient de Spearman évalue la corrélation de rang entre eux.\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.test.utils import datapath\n",
    "\n",
    "results = w2v_vectors.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
    "\n",
    "print(f\"Corrélation de Pearson : {results[0][0]:.4f}\")\n",
    "print(f\"Corrélation de Spearman : {results[1][0]:.4f}\")\n",
    "print(f\"Ratio de mots inconnus : {results[2]:.2f}%\")\n",
    "\n",
    "\"\"\"\n",
    "La fonction evaluate_word_pairs nous retourne trois métriques principales. Le coefficient de corrélation de Pearson est un tuple contenant le coefficient (un nombre entre -1 et 1) et sa valeur p associée, qui mesure la relation linéaire directe entre les similarités calculées par notre modèle et les jugements humains du dataset. Le coefficient de Spearman est également un tuple avec le coefficient et sa valeur p, mais qui s'intéresse plutôt à la corrélation des rangs (l'ordre) plutôt qu'aux valeurs absolues. Enfin, l'oov_ratio (out-of-vocabulary ratio) est un simple pourcentage qui indique la proportion de paires de mots qui n'existent pas dans le vocabulaire de notre modèle.\n",
    "\n",
    "Concernant les scores, ils sont calculés en comparant les similarités de paires de mots générées par le modèle avec les jugements humains du dataset WordSim-353. Le coefficient de corrélation de Pearson mesure la relation linéaire entre les deux ensembles de scores, tandis que le coefficient de Spearman évalue la corrélation de rang entre eux.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812b47ae81075948",
   "metadata": {},
   "source": [
    "### h. En vous aidant de la documentation, calculez le score du modèle word2vec sur les données  questions-words.txt. Attention, cette évaluation prend une dizaine de minutes, donc il vaut mieux commencer par tester avec un fragment de ce fichier (copier/coller les 100 premières analogies).  Expliquez en 1-2 phrases comment ce score est calculé et ce qu’il mesure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66010a3caeecaf6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T22:21:13.564977Z",
     "start_time": "2025-05-01T22:14:51.322861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nLa méthode evaluate_word_analogies() permet d\\'évaluer les capacités du modèle à résoudre des analogies linguistiques. Ces analogies prennent la forme \"A est à B ce que C est à D\", comme dans l\\'exemple \"homme est à femme ce que garçon est à fille\". Le modèle doit prédire le quatrième terme de l\\'analogie en utilisant l\\'opération vectorielle D = B - A + C. Cette opération consiste à partir du vecteur représentant le troisième mot (C), puis à y ajouter la différence entre les vecteurs des deux premiers mots (B - A). Le score obtenu représente le pourcentage d\\'analogies correctement résolues parmi l\\'ensemble du jeu de test. Ce score permet de mesurer la qualité des relations sémantiques et syntaxiques capturées par notre modèle Word2Vec. Plus le score est élevé, mieux le modèle a appris les relations entre les mots dans l\\'espace vectoriel.\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy_scores = w2v_vectors.evaluate_word_analogies(datapath('questions-words.txt'))\n",
    "print(f\"Score: {analogy_scores[0]:.4f}\")\n",
    "\n",
    "\"\"\"\n",
    "La méthode evaluate_word_analogies() permet d'évaluer les capacités du modèle à résoudre des analogies linguistiques. Ces analogies prennent la forme \"A est à B ce que C est à D\", comme dans l'exemple \"homme est à femme ce que garçon est à fille\". Le modèle doit prédire le quatrième terme de l'analogie en utilisant l'opération vectorielle D = B - A + C. Cette opération consiste à partir du vecteur représentant le troisième mot (C), puis à y ajouter la différence entre les vecteurs des deux premiers mots (B - A). Le score obtenu représente le pourcentage d'analogies correctement résolues parmi l'ensemble du jeu de test. Ce score permet de mesurer la qualité des relations sémantiques et syntaxiques capturées par notre modèle Word2Vec. Plus le score est élevé, mieux le modèle a appris les relations entre les mots dans l'espace vectoriel.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d92adf4",
   "metadata": {},
   "source": [
    "## Partie 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66ce2dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = api.load('text8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567dd101",
   "metadata": {},
   "source": [
    "### A) Combien de phrases et de mots (tokens) possède ce corpus ?\n",
    "\n",
    "Il y a 1701 phrases et 17005207 mots (tokens) dans le corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9550cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 1701\n",
      "Number of words: 17005207\n"
     ]
    }
   ],
   "source": [
    "# find number of sentences and words in the corpus\n",
    "num_sentences = 0\n",
    "num_words = 0\n",
    "for sentence in corpus:\n",
    "    num_sentences += 1\n",
    "    num_words += len(sentence)\n",
    "\n",
    "print(f\"Number of sentences: {num_sentences}\")\n",
    "print(f\"Number of words: {num_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61450355",
   "metadata": {},
   "source": [
    "### B) Entraînez un nouveau modèle word2vec sur ce nouveau corpus (voir la documentation de Word2vec). Si nécessaire, procédez progressivement, en commençant par utiliser 1% du corpus, puis 10%, etc., pour contrôler le temps nécessaire.\n",
    "\n",
    "> Veuillez indiquer la dimension choisie pour le embedding de ce nouveau modèle.\n",
    "\n",
    "Nous avons choisi une dimension de 100 pour le embedding du modèle.\n",
    "\n",
    "> Combien de temps prend l’entraînement sur le corpus total ?\n",
    "\n",
    "224 secondes pour entraîner le modèle sur le corpus total.\n",
    "\n",
    "> Quelle est la taille (en Mo) du modèle word2vec résultant ?\n",
    "\n",
    "56.47 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07c4ff90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 1% of the corpus...\n",
      "Training completed in 1.21 seconds\n",
      "Model size: 3.18 MB\n",
      "--------------------------------------------------\n",
      "Training on 10% of the corpus...\n",
      "Training completed in 14.61 seconds\n",
      "Model size: 15.41 MB\n",
      "--------------------------------------------------\n",
      "Training on 100% of the corpus...\n",
      "Training completed in 181.42 seconds\n",
      "Model size: 56.47 MB\n",
      "--------------------------------------------------\n",
      "Testing the full model:\n",
      "Most similar to 'king': [('kings', 0.7519744634628296), ('valdemar', 0.7400608658790588), ('sweyn', 0.7303428053855896), ('canute', 0.726966381072998), ('prince', 0.7269506454467773)]\n",
      "king - man + woman = [('daughter', 0.6498870849609375)]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "\n",
    "# Define embedding dimension\n",
    "vector_size = 100  # Dimension of word vectors\n",
    "\n",
    "# Convert corpus iterator to list for reusability\n",
    "corpus_list = list(corpus)\n",
    "\n",
    "# Function to train on a subset of the corpus\n",
    "def train_word2vec(corpus_data, subset_percentage=100):\n",
    "    subset_size = int(len(corpus_data) * subset_percentage / 100)\n",
    "    training_data = corpus_data[:subset_size]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train Word2Vec model\n",
    "    model = Word2Vec(\n",
    "        sentences=training_data,\n",
    "        vector_size=vector_size,  # Dimension of word vectors\n",
    "        window=5,                # Context window size\n",
    "        min_count=5,             # Minimum word count\n",
    "        workers=4,               # Number of threads\n",
    "        sg=1                     # Use skip-gram (sg=1) instead of CBOW (sg=0)\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    # Save model temporarily to measure its size\n",
    "    model_path = \"temp_w2v_model\"\n",
    "    model.save(model_path)\n",
    "    model_size_bytes = os.path.getsize(model_path)\n",
    "    model_size_mb = model_size_bytes / (1024 * 1024)\n",
    "    \n",
    "    return model, training_time, model_size_mb\n",
    "\n",
    "# Try with different subsets of the corpus\n",
    "percentages = [1, 10, 100]\n",
    "results = []\n",
    "\n",
    "for percentage in percentages:\n",
    "    print(f\"Training on {percentage}% of the corpus...\")\n",
    "    model, training_time, model_size = train_word2vec(corpus_list, percentage)\n",
    "    \n",
    "    results.append({\n",
    "        \"percentage\": percentage,\n",
    "        \"training_time\": training_time,\n",
    "        \"model_size_mb\": model_size,\n",
    "        \"model\": model\n",
    "    })\n",
    "    \n",
    "    print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "    print(f\"Model size: {model_size:.2f} MB\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# The full model is the last one in the results list\n",
    "full_model = results[-1][\"model\"]\n",
    "\n",
    "# Test the model with a few examples\n",
    "print(\"Testing the full model:\")\n",
    "try:\n",
    "    print(\"Most similar to 'king':\", full_model.wv.most_similar(\"king\", topn=5))\n",
    "    print(\"king - man + woman =\", full_model.wv.most_similar(positive=['king', 'woman'], negative=['man'], topn=1))\n",
    "except KeyError as e:\n",
    "    print(f\"Error: {e} - Word may not be in vocabulary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1888d8c3",
   "metadata": {},
   "source": [
    "### C) Mesurez la qualité de ce modèle comme en (1g) et (1h). Ce modèle est-il meilleur que celui entraîné sur Google News ? Quelle est selon vous la raison de la différence ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cfe09d",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "Score model entrainé sur Google News :\n",
    "Corrélation de Pearson : 0.6750\n",
    "Corrélation de Spearman : 0.6895\n",
    "Ratio de mots inconnus : 0.57%\n",
    "Score word analogy: 0.7401\n",
    "\n",
    "Score model entrainé par nous sur les premier charactères de wikipedia (en) :\n",
    "Corrélation de Pearson : 0.6750\n",
    "Corrélation de Spearman : 0.6895\n",
    "Ratio de mots inconnus : 0.57%\n",
    "Score word analogy: 0.2831\n",
    "```\n",
    "\n",
    "Le modèle entraîné sur le corpus de Google News est meilleur que celui entraîné sur le corpus Wikipedia. Cela peut être dû à la taille du corpus et à la qualité des données d'entraînement. Le corpus de Google News est plus vaste et contient des informations plus riches, ce qui permet au modèle d'apprendre des relations plus complexes entre les mots. De plus, le premier modèle a été pré-entrainé et a donc bénéficié de plus de temps d'entraînement et de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0894d9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrélation de Pearson : 0.6750\n",
      "Corrélation de Spearman : 0.6895\n",
      "Ratio de mots inconnus : 0.57%\n"
     ]
    }
   ],
   "source": [
    "full_model_vectors = full_model.wv\n",
    "results = full_model_vectors.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
    "\n",
    "print(f\"Corrélation de Pearson : {results[0][0]:.4f}\")\n",
    "print(f\"Corrélation de Spearman : {results[1][0]:.4f}\")\n",
    "print(f\"Ratio de mots inconnus : {results[2]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a12da623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.2831\n"
     ]
    }
   ],
   "source": [
    "analogy_scores = full_model_vectors.evaluate_word_analogies(datapath('questions-words.txt'))\n",
    "print(f\"Score: {analogy_scores[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b05bdf",
   "metadata": {},
   "source": [
    "### D) Entraînez un nouveau modèle word2vec sur ce corpus, en précisant la dimension choisie pour les embeddings.\n",
    "\n",
    "> Combien de temps prend l’entraînement ?\n",
    "\n",
    "21 minutes pour entraîner le modèle sur le corpus total.\n",
    "\n",
    "> Quelle est la taille (en Mo) du modèle word2vec résultant ?\n",
    "\n",
    "3.71 MB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db8d9ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading corpus using Text8Corpus...\n",
      "Corpus statistics:\n",
      "Number of sentences: 7011\n",
      "Number of words: 70102071\n",
      "Using vector size: 100\n",
      "Training Word2Vec model on the augmented corpus...\n",
      "Training completed in 1306.65 seconds (21.78 minutes)\n",
      "Model size: 3.71 MB\n",
      "\n",
      "Testing the augmented model:\n",
      "Most similar to 'king': [('adulyadej', 0.6732905507087708), ('bkcn', 0.6676017642021179), ('hrh', 0.6639602780342102), ('bkcbkul', 0.6561483144760132), ('burger', 0.6552857756614685)]\n",
      "king - man + woman = [('laird', 0.6117794513702393)]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "\n",
    "dat_file_path = \"wikipedia_augmented.dat\" \n",
    "\n",
    "# Load corpus using Text8Corpus class\n",
    "print(\"Loading corpus using Text8Corpus...\")\n",
    "text8_corpus = Text8Corpus(dat_file_path)\n",
    "\n",
    "# Print corpus statistics\n",
    "print(f\"Corpus statistics:\")\n",
    "num_sentences_t8 = len(list(text8_corpus))\n",
    "num_words_t8 = sum(len(sentence) for sentence in text8_corpus)\n",
    "print(f\"Number of sentences: {num_sentences_t8}\")\n",
    "print(f\"Number of words: {num_words_t8}\")\n",
    "\n",
    "# Reset the corpus iterator\n",
    "text8_corpus = Text8Corpus(dat_file_path)\n",
    "\n",
    "# We use the same vector size as defined previously\n",
    "print(f\"Using vector size: {vector_size}\")\n",
    "\n",
    "\n",
    "print(\"Training Word2Vec model on the augmented corpus...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Train Word2Vec model\n",
    "augmented_model = Word2Vec(\n",
    "    sentences=text8_corpus,\n",
    "    vector_size=vector_size,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    workers=4,\n",
    "    sg=1  # Use skip-gram\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Save model temporarily to measure its size\n",
    "model_path = \"augmented_w2v_model\"\n",
    "augmented_model.save(model_path)\n",
    "model_size_bytes = os.path.getsize(model_path)\n",
    "model_size_mb = model_size_bytes / (1024 * 1024)\n",
    "\n",
    "print(f\"Training completed in {training_time:.2f} seconds ({training_time/60:.2f} minutes)\")\n",
    "print(f\"Model size: {model_size_mb:.2f} MB\")\n",
    "\n",
    "# Test the model with a few examples\n",
    "print(\"\\nTesting the augmented model:\")\n",
    "try:\n",
    "    print(\"Most similar to 'king':\", augmented_model.wv.most_similar(\"king\", topn=5))\n",
    "    print(\"king - man + woman =\", augmented_model.wv.most_similar(positive=['king', 'woman'], \n",
    "                                                                negative=['man'], topn=1))\n",
    "except KeyError as e:\n",
    "    print(f\"Error: {e} - Word may not be in vocabulary\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47a20fd",
   "metadata": {},
   "source": [
    "### E) Testez ce modèle comme en (1g) et (1h). Est-il meilleur que le précédent ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf07b17a",
   "metadata": {},
   "source": [
    "```\n",
    "Score model entrainé sur Google News :\n",
    "Corrélation de Pearson : 0.6750\n",
    "Corrélation de Spearman : 0.6895\n",
    "Ratio de mots inconnus : 0.57%\n",
    "Score word analogy: 0.7401\n",
    "\n",
    "Score model entrainé par nous sur les premier charactères de wikipedia (en) :\n",
    "Corrélation de Pearson : 0.6750\n",
    "Corrélation de Spearman : 0.6895\n",
    "Ratio de mots inconnus : 0.57%\n",
    "Score word analogy: 0.2831\n",
    "\n",
    "Score model entrainé sur wikipedia_augmented :\n",
    "Corrélation de Pearson : 0.5112\n",
    "Corrélation de Spearman : 0.5026\n",
    "Ratio de mots inconnus : 0.00%\n",
    "Score: 0.3238\n",
    "```\n",
    "\n",
    "Le modèle entraîné sur Wikipedia_augmented présente ces avantages par rapport au modèle Text8 (premiers caractères de Wikipedia):\n",
    "\n",
    "* Meilleure couverture lexicale (0% de mots inconnus contre 0.57%)\n",
    "* Score d'analogie supérieur (0.3238 contre 0.2831)\n",
    "\n",
    "Cependant, le modèle Text8 offre de meilleures corrélations avec les jugements humains de similarité (Pearson et Spearman).\n",
    "\n",
    "Aucun des deux modèles n'égale les performances du modèle pré-entraîné sur Google News, qui reste supérieur sur tous les critères d'évaluation, probablement grâce à son corpus d'entraînement plus vaste et diversifié.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f72b6088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrélation de Pearson : 0.5112\n",
      "Corrélation de Spearman : 0.5026\n",
      "Ratio de mots inconnus : 0.00%\n"
     ]
    }
   ],
   "source": [
    "text8_model_vectors = augmented_model.wv\n",
    "results = text8_model_vectors.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
    "\n",
    "print(f\"Corrélation de Pearson : {results[0][0]:.4f}\")\n",
    "print(f\"Corrélation de Spearman : {results[1][0]:.4f}\")\n",
    "print(f\"Ratio de mots inconnus : {results[2]:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0920f261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.3238\n"
     ]
    }
   ],
   "source": [
    "analogy_scores = text8_model_vectors.evaluate_word_analogies(datapath('questions-words.txt'))\n",
    "print(f\"Score: {analogy_scores[0]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
