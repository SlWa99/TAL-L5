{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tester et évaluer un modèle déjà entraîné sur Google News\n",
   "id": "c9596f7a87b82732"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Téléchargement du modèle word2vec pré entrainé sur le corpus de Google News",
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:53:39.359170Z",
     "start_time": "2025-05-01T21:53:38.961976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim import downloader as api\n",
    "path_to_file = api.load(\"word2vec-google-news-300\", return_path=True)"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:54:21.810094Z",
     "start_time": "2025-05-01T21:53:40.281320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.models import KeyedVectors\n",
    "w2v_vectors = KeyedVectors.load_word2vec_format(path_to_file, binary=True)"
   ],
   "id": "e00a01710ba3ec5b",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### a. Quelle place en mémoire occupe le processus du notebook avec les vecteurs de mots ?",
   "id": "66c14df69a6edac1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:54:34.317110Z",
     "start_time": "2025-05-01T21:54:34.307871Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Taille du notebook : {w2v_vectors.vectors.nbytes / (1024 ** 2):.2f} MB\")",
   "id": "c2fe61cf4f5afab5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du notebook : 3433.23 MB\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### b. Quelle est la dimension de l’espace vectoriel dans lequel les mots sont représentés ?",
   "id": "a3105ddbc17f1620"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:54:36.035848Z",
     "start_time": "2025-05-01T21:54:36.029615Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Les vecteurs de mots ont une dimension de : {w2v_vectors.vector_size} dimensions\")",
   "id": "4b472b8c6fa51ec5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les vecteurs de mots ont une dimension de : 300 dimensions\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### c. Quelle est la taille du vocabulaire connu du modèle ?  Veuillez afficher cinq mots anglais qui sont dans le vocabulaire et deux qui ne le sont pas.",
   "id": "774852931cee8802"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:54:37.415153Z",
     "start_time": "2025-05-01T21:54:37.408156Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\" Taille du vocabulaire : {len(w2v_vectors.key_to_index)} mots\")",
   "id": "c8fd57e258d64055",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Taille du vocabulaire : 3000000 mots\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:54:38.913712Z",
     "start_time": "2025-05-01T21:54:38.860529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "sample_words = random.sample(list(w2v_vectors.key_to_index.keys()), 5)\n",
    "print(\"Exemples de mots connus du modèle :\", sample_words)"
   ],
   "id": "9b5bb40e79fda7b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemples de mots connus du modèle : ['Isaac_Tshuva', 'By_LORA_HINES', 'Stephane_Bre', 'hepatic_enzyme', 'HBTC']\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:54:40.164341Z",
     "start_time": "2025-05-01T21:54:40.139002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unknown = [\"horloge\", \"Horloge\",\"Huitante\", \"huitante\", \"Altruiste\", \"altruiste\" ,\"montre\", \"Montre\", \"MoNtRe\"]\n",
    "print(\"Ces mots sont-ils dans le vocabulaire ?\")\n",
    "for word in unknown:\n",
    "    print(f\"{word} : {'Oui' if word in w2v_vectors else 'Non'}\")\n",
    "\n",
    "\"\"\"\n",
    "C'est étonnant que le mot \"horloge\" ne soit pas dans le vocabulaire, car il est très courant en français. De plus, on peut voir que \"Horloge\" est dans le vocabulaire du modèle. Grâce aux tests effectués sur le mot \"montre\", on peut voir que le modèle est sensible à la casse.\n",
    "\"\"\""
   ],
   "id": "b09fb71957753bd6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ces mots sont-ils dans le vocabulaire ?\n",
      "horloge : Non\n",
      "Horloge : Oui\n",
      "Huitante : Non\n",
      "huitante : Non\n",
      "Altruiste : Non\n",
      "altruiste : Non\n",
      "montre : Oui\n",
      "Montre : Oui\n",
      "MoNtRe : Non\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nC\\'est étonnant que le mot \"horloge\" ne soit pas dans le vocabulaire, car il est très courant en français. De plus, on peut voir que \"Horloge\" est dans le vocabulaire du modèle. Grâce aux tests effectués sur le mot \"montre\", on peut voir que le modèle est sensible à la casse.\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### d. Quelle est la similarité entre les mots rabbit et carrot ?  Veuillez rappeler comment on mesure les similarités entre deux mots grâce à leurs vecteurs.",
   "id": "84e4e67d0dfe807b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:54:42.667093Z",
     "start_time": "2025-05-01T21:54:42.639425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Similarité entre les mots 'rabbit' et 'carrot' : {w2v_vectors.similarity('rabbit', 'carrot'):.4f}\")\n",
    "\n",
    "\"\"\"\n",
    "La similarité entre deux mots est mesurée par le produit scalaire de leurs vecteurs, normalisé par la norme de chacun des vecteurs. En d'autres termes, la similarité entre deux mots est donnée par la formule : Similiarité(a, b) = a * b / ||a|| * ||b||.\n",
    "\"\"\""
   ],
   "id": "dcdf1b60bf236296",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarité entre les mots 'rabbit' et 'carrot' : 0.3631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nLa similarité entre deux mots est mesurée par le produit scalaire de leurs vecteurs, normalisé par la norme de chacun des vecteurs. En d'autres termes, la similarité entre deux mots est donnée par la formule : Similiarité(a, b) = a * b / ||a|| * ||b||.\\n\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### e. Considérez au moins 5 paires de mots anglais, certains proches par leurs sens, d’autres plus éloignés. Pour chaque paire, calculez la similarité entre les deux mots.  Veuillez indiquer si les similarités obtenues correspondent à vos intuitions sur la proximité des sens des mots.",
   "id": "e96b1e08ab54e11e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:54:46.075359Z",
     "start_time": "2025-05-01T21:54:46.050687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "word_pairs = [(\"king\", \"queen\"), (\"cat\", \"tiger\"), (\"computer\", \"tree\"), (\"wheel\", \"spider\"), (\"security\", \"byte\")]\n",
    "\n",
    "for word1, word2 in word_pairs:\n",
    "    similarity = w2v_vectors.similarity(word1, word2)\n",
    "    print(f\"Similarité entre '{word1}' et '{word2}' : {similarity:.4f}\")\n",
    "\n",
    "\"\"\"\n",
    "De manière générale, les similarités obtenues correspondent à nos intuitions. Toutefois, nous aurions pensé que la similiarité entre \"computer\" et \"tree\"serait plus élevée. Le modèle doit très certaienemnt comprendre le mot \"tree\" comme étant un arbre dans une forêt, et non une structure informatique. Le constat est le même pour \"securtiy\" et \"byte\". Pour ce cas de figure, on peut penser que le score obtenu est légitime car le mot \"security\" est trop général et peut être utilisé dans de nombreux contextes.\n",
    "\"\"\""
   ],
   "id": "b13814b86e759a37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarité entre 'king' et 'queen' : 0.6511\n",
      "Similarité entre 'cat' et 'tiger' : 0.5173\n",
      "Similarité entre 'computer' et 'tree' : 0.1062\n",
      "Similarité entre 'wheel' et 'spider' : 0.1464\n",
      "Similarité entre 'security' et 'byte' : 0.1081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nDe manière générale, les similarités obtenues correspondent à nos intuitions. Toutefois, nous aurions pensé que la similiarité entre \"computer\" et \"tree\"serait plus élevée. Le modèle doit très certaienemnt comprendre le mot \"tree\" comme étant un arbre dans une forêt, et non une structure informatique. Le constat est le même pour \"securtiy\" et \"byte\". Pour ce cas de figure, on peut penser que le score obtenu est légitime car le mot \"security\" est trop général et peut être utilisé dans de nombreux contextes.\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### f. Pouvez-vous trouver des mots de sens opposés mais qui sont proches selon le modèle ? Comment expliquez-vous cela ?  Est-ce une qualité ou un défaut du modèle word2vec ?",
   "id": "897822d61644fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:54:48.849720Z",
     "start_time": "2025-05-01T21:54:48.825554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "word_pairs = [\n",
    "    (\"win\", \"lose\"),\n",
    "    (\"day\", \"night\"),\n",
    "    (\"love\", \"hate\"),\n",
    "    (\"walk\", \"drive\"),\n",
    "    (\"up\", \"down\"),\n",
    "    (\"happy\", \"sad\"),\n",
    "    (\"light\", \"dark\"),\n",
    "    (\"success\", \"failure\"),\n",
    "    (\"young\", \"old\"),\n",
    "    (\"strong\", \"weak\"),\n",
    "    (\"enter\", \"exit\"),\n",
    "    (\"increase\", \"decrease\"),\n",
    "    (\"begin\", \"end\"),\n",
    "    (\"open\", \"close\"),\n",
    "    (\"true\", \"false\")\n",
    "]\n",
    "\n",
    "for word1, word2 in word_pairs:\n",
    "    similarity = w2v_vectors.similarity(word1, word2)\n",
    "    print(f\"Similarité entre '{word1}' et '{word2}' : {similarity:.4f}\")\n",
    "\n",
    "\"\"\"\n",
    "Dans nos résultats, nous pouvons constater que plusieurs paires de mots opposés ont des similarités étonnamment élevées. Le cas le plus frappant est \"increase\" et \"decrease\" avec un score de 0.84, mais on observe aussi des valeurs élevées pour \"up/down\" (0.64) et \"strong/weak\" (0.62).\n",
    "\n",
    "On pourrait s'attendre à ce que des antonymes aient une similarité plus basse. En réalité, Word2Vec capture les relations contextuelles entre les mots. Dans les textes, ces paires d'opposés apparaissent souvent ensemble - quand on parle d'augmentation, la diminution est fréquemment mentionnée aussi.\n",
    "\n",
    "Pouvons nous voir cela comme une qualité ou un défaut du modèle ? D'un côté, cela illustre que Word2Vec comprend les relations conceptuelles entre les mots car les antonymes font bien partie du même champ sémantique / lexicale. D'un autre côté, pour des applications comme l'analyse de sentiment, cette caractéristique pourrait être problématique. Cela représente davantage une caractéristique fondamentale du modèle qu'un véritable défaut.\n",
    "\"\"\""
   ],
   "id": "29e5015cbc52d0a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarité entre 'win' et 'lose' : 0.3951\n",
      "Similarité entre 'day' et 'night' : 0.5070\n",
      "Similarité entre 'love' et 'hate' : 0.6004\n",
      "Similarité entre 'walk' et 'drive' : 0.3630\n",
      "Similarité entre 'up' et 'down' : 0.6397\n",
      "Similarité entre 'happy' et 'sad' : 0.5355\n",
      "Similarité entre 'light' et 'dark' : 0.4713\n",
      "Similarité entre 'success' et 'failure' : 0.3241\n",
      "Similarité entre 'young' et 'old' : 0.4174\n",
      "Similarité entre 'strong' et 'weak' : 0.6157\n",
      "Similarité entre 'enter' et 'exit' : 0.3563\n",
      "Similarité entre 'increase' et 'decrease' : 0.8370\n",
      "Similarité entre 'begin' et 'end' : 0.3478\n",
      "Similarité entre 'open' et 'close' : 0.4637\n",
      "Similarité entre 'true' et 'false' : 0.3709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nDans nos résultats, nous pouvons constater que plusieurs paires de mots opposés ont des similarités étonnamment élevées. Le cas le plus frappant est \"increase\" et \"decrease\" avec un score de 0.84, mais on observe aussi des valeurs élevées pour \"up/down\" (0.64) et \"strong/weak\" (0.62).\\n\\nOn pourrait s\\'attendre à ce que des antonymes aient une similarité plus basse. En réalité, Word2Vec capture les relations contextuelles entre les mots. Dans les textes, ces paires d\\'opposés apparaissent souvent ensemble - quand on parle d\\'augmentation, la diminution est fréquemment mentionnée aussi.\\n\\nPouvons nous voir cela comme une qualité ou un défaut du modèle ? D\\'un côté, cela illustre que Word2Vec comprend les relations conceptuelles entre les mots car les antonymes font bien partie du même champ sémantique / lexicale. D\\'un autre côté, pour des applications comme l\\'analyse de sentiment, cette caractéristique pourrait être problématique. Cela représente davantage une caractéristique fondamentale du modèle qu\\'un véritable défaut.\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### g. En vous aidant de la documentation de Gensim sur KeyedVectors, obtenez les scores du modèle word2vec sur les données de test WordSimilarity-353. Veuillez rappeler en 1-2 phrases comment les différents scores sont calculés.",
   "id": "a9fe4d7ef4902512"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T21:54:52.958645Z",
     "start_time": "2025-05-01T21:54:52.537543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.test.utils import datapath\n",
    "\n",
    "results = w2v_vectors.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
    "\n",
    "print(f\"Corrélation de Pearson : {results[0][0]:.4f}\")\n",
    "print(f\"Corrélation de Spearman : {results[1][0]:.4f}\")\n",
    "print(f\"Ratio de mots inconnus : {results[2]:.2f}%\")\n",
    "\n",
    "\"\"\"\n",
    "La fonction evaluate_word_pairs nous retourne trois métriques principales. Le coefficient de corrélation de Pearson est un tuple contenant le coefficient (un nombre entre -1 et 1) et sa valeur p associée, qui mesure la relation linéaire directe entre les similarités calculées par notre modèle et les jugements humains du dataset. Le coefficient de Spearman est également un tuple avec le coefficient et sa valeur p, mais qui s'intéresse plutôt à la corrélation des rangs (l'ordre) plutôt qu'aux valeurs absolues. Enfin, l'oov_ratio (out-of-vocabulary ratio) est un simple pourcentage qui indique la proportion de paires de mots qui n'existent pas dans le vocabulaire de notre modèle.\n",
    "\n",
    "Concernant les scores, ils sont calculés en comparant les similarités de paires de mots générées par le modèle avec les jugements humains du dataset WordSim-353. Le coefficient de corrélation de Pearson mesure la relation linéaire entre les deux ensembles de scores, tandis que le coefficient de Spearman évalue la corrélation de rang entre eux.\n",
    "\"\"\""
   ],
   "id": "e3adbdf1bb953cc6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrélation de Pearson : 0.6239\n",
      "Corrélation de Spearman : 0.6589\n",
      "Ratio de mots inconnus : 0.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nLa fonction evaluate_word_pairs nous retourne trois métriques principales. Le coefficient de corrélation de Pearson est un tuple contenant le coefficient (un nombre entre -1 et 1) et sa valeur p associée, qui mesure la relation linéaire directe entre les similarités calculées par notre modèle et les jugements humains du dataset. Le coefficient de Spearman est également un tuple avec le coefficient et sa valeur p, mais qui s'intéresse plutôt à la corrélation des rangs (l'ordre) plutôt qu'aux valeurs absolues. Enfin, l'oov_ratio (out-of-vocabulary ratio) est un simple pourcentage qui indique la proportion de paires de mots qui n'existent pas dans le vocabulaire de notre modèle.\\n\\nConcernant les scores, ils sont calculés en comparant les similarités de paires de mots générées par le modèle avec les jugements humains du dataset WordSim-353. Le coefficient de corrélation de Pearson mesure la relation linéaire entre les deux ensembles de scores, tandis que le coefficient de Spearman évalue la corrélation de rang entre eux.\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### h. En vous aidant de la documentation, calculez le score du modèle word2vec sur les données  questions-words.txt. Attention, cette évaluation prend une dizaine de minutes, donc il vaut mieux commencer par tester avec un fragment de ce fichier (copier/coller les 100 premières analogies).  Expliquez en 1-2 phrases comment ce score est calculé et ce qu’il mesure.",
   "id": "812b47ae81075948"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T22:21:13.564977Z",
     "start_time": "2025-05-01T22:14:51.322861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "analogy_scores = w2v_vectors.evaluate_word_analogies(datapath('questions-words.txt'))\n",
    "print(f\"Score: {analogy_scores[0]:.4f}\")\n",
    "\n",
    "\"\"\"\n",
    "La méthode evaluate_word_analogies() permet d'évaluer les capacités du modèle à résoudre des analogies linguistiques. Ces analogies prennent la forme \"A est à B ce que C est à D\", comme dans l'exemple \"homme est à femme ce que garçon est à fille\". Le modèle doit prédire le quatrième terme de l'analogie en utilisant l'opération vectorielle D = B - A + C. Cette opération consiste à partir du vecteur représentant le troisième mot (C), puis à y ajouter la différence entre les vecteurs des deux premiers mots (B - A). Le score obtenu représente le pourcentage d'analogies correctement résolues parmi l'ensemble du jeu de test. Ce score permet de mesurer la qualité des relations sémantiques et syntaxiques capturées par notre modèle Word2Vec. Plus le score est élevé, mieux le modèle a appris les relations entre les mots dans l'espace vectoriel.\n",
    "\"\"\""
   ],
   "id": "66010a3caeecaf6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nLa méthode evaluate_word_analogies() permet d\\'évaluer les capacités du modèle à résoudre des analogies linguistiques. Ces analogies prennent la forme \"A est à B ce que C est à D\", comme dans l\\'exemple \"homme est à femme ce que garçon est à fille\". Le modèle doit prédire le quatrième terme de l\\'analogie en utilisant l\\'opération vectorielle D = B - A + C. Cette opération consiste à partir du vecteur représentant le troisième mot (C), puis à y ajouter la différence entre les vecteurs des deux premiers mots (B - A). Le score obtenu représente le pourcentage d\\'analogies correctement résolues parmi l\\'ensemble du jeu de test. Ce score permet de mesurer la qualité des relations sémantiques et syntaxiques capturées par notre modèle Word2Vec. Plus le score est élevé, mieux le modèle a appris les relations entre les mots dans l\\'espace vectoriel.\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
